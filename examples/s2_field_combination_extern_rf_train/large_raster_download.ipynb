{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoengine as ge\n",
    "import math\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Geo Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge.initialize(\"http://pc12730.mathematik.uni-marburg.de:3031/api\", credentials=(\"admin@localhost\", \"adminadmin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Server:              http://pc12730.mathematik.uni-marburg.de:3031/api\n",
       "User Id:             d5328854-6190-4af9-ad69-4e74b0961ac9\n",
       "Session Id:          6626ddb1-6bd5-44cc-9063-1113c00f6ac4\n",
       "Session valid until: 2024-04-24T20:25:58.595Z"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = ge.get_session()\n",
    "user_id = session.user_id\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information about the bands we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_resolutions = {\n",
    "    \"10\": [\"B02\", \"B03\", \"B04\", \"B08\"],    \n",
    "    \"20\": [\"B11\", \"B12\", \"SCL\"]\n",
    "}\n",
    "\n",
    "band_names = [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\"]\n",
    "scl_name = \"SCL\"\n",
    "\n",
    "def get_band_resolution(band_name):\n",
    "    if band_name ==\"NDVI\":\n",
    "        return 10\n",
    "\n",
    "    for (res, bands) in band_resolutions.items():\n",
    "        if band_name in bands:\n",
    "            return float(res)\n",
    "    return None\n",
    "\n",
    "def get_resoluton_bands(res):\n",
    "    return band_resolutions[res]\n",
    "\n",
    "get_band_resolution(\"B02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tiles we want to use and way to modify the bounds to match the pixel resolution of the band (also use a power of 2 because it is nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [677420, 5845280, 718380, 5886240]\n",
      "1 40960 40960\n",
      "2 [683860, 5368240, 724820, 5409200]\n",
      "2 40960 40960\n",
      "3 [441200, 5683040, 482160, 5724000]\n",
      "3 40960 40960\n",
      "4 [364960, 5443480, 405920, 5484440]\n",
      "4 40960 40960\n",
      "5 [478740, 5842520, 519700, 5883480]\n",
      "5 40960 40960\n",
      "6 [555400, 6042340, 596360, 6083300]\n",
      "6 40960 40960\n",
      "7 [560940, 5644940, 601900, 5685900]\n",
      "7 40960 40960\n",
      "8 [717740, 5806100, 758700, 5847060]\n",
      "8 40960 40960\n",
      "9 [403620, 5523540, 444580, 5564500]\n",
      "9 40960 40960\n",
      "10 [475960, 6041220, 516920, 6082180]\n",
      "10 40960 40960\n"
     ]
    }
   ],
   "source": [
    "def next_power_of_2(x):\n",
    "    return 1 if x == 0 else 2**math.ceil(math.log2(x))\n",
    "\n",
    "def better_tile_bounds(xmin, ymin, xmax, ymax, res):\n",
    "    size_x = xmax - xmin\n",
    "    size_y = ymax - ymin\n",
    "    x_start = int(xmin/res)*res\n",
    "    y_start = int(ymin/res)*res\n",
    "    x_end = x_start + next_power_of_2(size_x/res)*res\n",
    "    y_end = y_start + next_power_of_2(size_y/res)*res\n",
    "    return [x_start, y_start, x_end, y_end]\n",
    "\n",
    "\n",
    "tiles = {\n",
    "    \"1\": [677434.81148609332740307, 5845298.07400647643953562, 717747.09661422134377062, 5885618.66241065505892038], # 1\n",
    "    \"2\": [683873.44084652571473271, 5368245.35890970937907696, 724127.46885261742863804, 5408501.99355369247496128], # 2\n",
    "    \"3\": [441200.25685675046406686, 5683048.10977123398333788, 481481.32107784802792594 , 5723328.07085583545267582], # 3\n",
    "    \"4\": [364967.8289228081703186,  5443493.64452091883867979, 405243.77002240129513666,  5483803.21444271318614483], # 4\n",
    "    \"5\": [478746.69248974783113226, 5842533.08955569006502628, 519031.87294624710921198, 5882816.76165715791285038],  # 5\n",
    "    \"6\": [555410.59772756404709071, 6042341.78814582619816065, 595702.63884835026692599, 6082661.56917595490813255], # 6\n",
    "    \"7\": [560953.47924317768774927, 5644941.74779673106968403, 601231.64683432993479073, 5685220.59041254408657551], # 7\n",
    "    \"8\": [717747.09661422134377062, 5806104.44838424492627382, 758067.72125238052103668, 5846427.60958131216466427], # 8\n",
    "    \"9\": [403628.38119195553008467, 5523546.04429935291409492, 443903.65706163534196094, 5563838.3149972390383482], # 9\n",
    "    \"10\": [475968.06303980643860996, 6041234.39164876379072666, 516251.6795115998829715, 6081531.74282156955450773] # 10\n",
    "}\n",
    "\n",
    "max_pixel_size = int(get_band_resolution(\"B12\"))\n",
    "\n",
    "better_tiles = {b: better_tile_bounds(*tiles[b], max_pixel_size) for b in tiles}\n",
    "\n",
    "for (tile, tile_bounds) in better_tiles.items():\n",
    "    print(tile, tile_bounds)\n",
    "    [xmin, ymin, xmax, ymax] = tile_bounds\n",
    "    size_x = xmax - xmin\n",
    "    size_y = ymax - ymin\n",
    "    print(tile, size_x, size_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, the tiles are stored as different datasets. Here is a simple way to resolve there names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d5328854-6190-4af9-ad69-4e74b0961ac9:lena_sentinel2_10m_tile_10_band_B02_2022_2023'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataset_name(user_id, tile, band):\n",
    "    band_resolution = int(get_band_resolution(band))\n",
    "    return f\"{user_id}:lena_sentinel2_{band_resolution}m_tile_{tile}_band_{band}_2022_2023\"\n",
    "\n",
    "get_dataset_name(user_id, \"10\", \"B02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Geo Engine uses a `QueryRectangle` to request the data. It specifies the bounding box of the area of interest and the time range. (The resolution is also specified here, but this will change in the near future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryRectangle( \n",
       "    BoundingBox2D(xmin=475960, ymin=6041220, xmax=516920, ymax=6082180)\n",
       "    TimeInterval(start=2022-01-01T00:00:00.000000, end=2023-01-01T00:00:00.000000)\n",
       "    SpatialResolution(x=10.0, y=10.0)\n",
       "    srs=EPSG:32632 \n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_query(bounds, resolution, time_start, time_end):\n",
    "    [xmin, ymin, xmax, ymax] = bounds\n",
    "    return ge.QueryRectangle(\n",
    "        spatial_bounds=ge.BoundingBox2D(xmin, ymin, xmax, ymax),\n",
    "        time_interval=ge.TimeInterval(time_start, time_end),\n",
    "        resolution=ge.SpatialResolution(resolution, resolution),\n",
    "        srs=\"EPSG:32632\"\n",
    "    )\n",
    "\n",
    "time_start = datetime(2022, 1, 1)\n",
    "time_end = datetime(2023, 1, 1)\n",
    "    \n",
    "create_query(better_tiles[\"10\"], 10.0, time_start, time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "\n",
    "class RasterWorkflowGdalWriter:\n",
    "    current_dataset: gdal.Dataset = None\n",
    "    current_time: ge.TimeInterval = None\n",
    "    dataset_geo_transform = None\n",
    "    dataset_width = None\n",
    "    dataset_height = None\n",
    "    dataset_data_type = gdal.GDT_Float32\n",
    "    print_info = False\n",
    "\n",
    "\n",
    "    dataset_prefix = None\n",
    "    workflow: ge.Workflow = None\n",
    "    bands = None\n",
    "    no_data_value = 0 # TODO: add type cast\n",
    "    time_format = \"%Y-%m-%d_%H-%M-%S\"\n",
    "\n",
    "    gdal_driver = \"GTiff\"\n",
    "    options = [\"TILED=YES\", \"COMPRESS=DEFLATE\", \"ZLEVEL=9\"]\n",
    "    tile_size = 512\n",
    "    \n",
    "    def __init__(self, dataset_prefix, workflow: ge.Workflow, no_data_value=0, data_type=gdal.GDT_Float32, print_info=False):\n",
    "        self.dataset_prefix = dataset_prefix\n",
    "        self.workflow = workflow\n",
    "        self.no_data_value = no_data_value\n",
    "        self.dataset_data_type = data_type\n",
    "        self.print_info = print_info\n",
    "\n",
    "        ras_res = cast(ge.RasterResultDescriptor, self.workflow.get_result_descriptor())\n",
    "        self.bands = ras_res.bands\n",
    "\n",
    "    def close_current_dataset(self):\n",
    "        if self.current_dataset:\n",
    "            self.current_dataset = None\n",
    "\n",
    "    def create_tiling_geo_transform_width_height(self, query: ge.QueryRectangle):\n",
    "\n",
    "        ul_x = query.spatial_bounds.xmin\n",
    "        ul_y = query.spatial_bounds.ymax\n",
    "        lr_x = query.spatial_bounds.xmax\n",
    "        lr_y = query.spatial_bounds.ymin\n",
    "        res_x = query.spatial_resolution.x_resolution\n",
    "        res_y = query.spatial_resolution.y_resolution * -1 # honor the fact that the y axis is flipped\n",
    "\n",
    "        assert res_y < 0, \"The y resolution must be negative\"\n",
    "\n",
    "        assert ul_x < lr_x, \"The upper left x coordinate must be smaller than the lower right x coordinate\"\n",
    "        assert ul_y > lr_y, \"The upper left y coordinate must be greater than the lower right y coordinate\"\n",
    "\n",
    "        ul_pixel_x = ul_x / res_x # we can assume that the global origin is 0,0\n",
    "        ul_pixel_y = ul_y / res_y\n",
    "        lr_pixel_x = lr_x / res_x\n",
    "        lr_pixel_y = lr_y / res_y\n",
    "\n",
    "        assert ul_pixel_x < lr_pixel_x, \"The upper left pixel x must be smaller than the lower right pixel x\"\n",
    "        assert ul_pixel_y < lr_pixel_y, \"The upper left pixel y must be smaller than the lower right pixel y\"\n",
    "\n",
    "        tiling_ul_pixel_x = (ul_pixel_x // self.tile_size) * self.tile_size\n",
    "        if ul_pixel_x % self.tile_size != 0:\n",
    "                tiling_ul_pixel_x = ((ul_pixel_x // self.tile_size) -1 ) * self.tile_size\n",
    "        \n",
    "        tiling_ul_pixel_y = (ul_pixel_y // self.tile_size) * self.tile_size\n",
    "        if ul_pixel_y % self.tile_size != 0:            \n",
    "                tiling_ul_pixel_y = ((ul_pixel_y // self.tile_size) -1 ) * self.tile_size\n",
    "\n",
    "        assert tiling_ul_pixel_x <= ul_pixel_x, \"The tiling upper left x pixel must be smaller than the upper left x coordinate\"\n",
    "        assert tiling_ul_pixel_y <= ul_pixel_y, \"The tiling upper left y pixel must be smaller than the upper left y coordinate\"\n",
    "                \n",
    "        width = int((lr_pixel_x - tiling_ul_pixel_x))\n",
    "        if width % self.tile_size != 0:\n",
    "            width = int((width // self.tile_size + 1) * self.tile_size)\n",
    "        assert width > 0, \"The width must be greater than 0\"\n",
    "\n",
    "        height = int((lr_pixel_y - tiling_ul_pixel_y ))\n",
    "        if height % self.tile_size != 0:\n",
    "            height = int((height // self.tile_size + 1) * self.tile_size)\n",
    "        assert height > 0, \"The height must be greater than 0\"\n",
    "        \n",
    "        assert width % self.tile_size == 0, \"The width must be a multiple of the tile size\"\n",
    "        assert height % self.tile_size == 0, \"The height must be a multiple of the tile size\"\n",
    "\n",
    "        tiling_ul_x_coord = tiling_ul_pixel_x * res_x\n",
    "        tiling_ul_y_coord = tiling_ul_pixel_y * res_y\n",
    "        assert tiling_ul_x_coord <= ul_x, \"The tiling upper left x coordinate must be smaller than the upper left x coordinate\"\n",
    "        assert tiling_ul_y_coord >= ul_y, \"The tiling upper left y coordinate must be greater than the upper left y coordinate\"\n",
    "\n",
    "        geo_transform = (tiling_ul_x_coord, res_x, 0, tiling_ul_y_coord, 0, res_y)\n",
    "\n",
    "        if self.dataset_geo_transform is None:\n",
    "            self.dataset_geo_transform = geo_transform\n",
    "        else:\n",
    "            assert self.dataset_geo_transform == geo_transform, \"The geo transform of the current dataset does not match the new one\"\n",
    "\n",
    "        if self.dataset_width is None:\n",
    "            self.dataset_width = width\n",
    "        else:\n",
    "            assert self.dataset_width == width, \"The width of the current dataset does not match the new one\"\n",
    "\n",
    "        if self.dataset_height is None:\n",
    "            self.dataset_height = height\n",
    "        else:\n",
    "            assert self.dataset_height == height, \"The height of the current dataset does not match the new one\"        \n",
    "\n",
    "\n",
    "    def create_new_dataset(self, query: ge.QueryRectangle):\n",
    "        \n",
    "        time_formated_start = self.current_time.start.astype(datetime).strftime(self.time_format)\n",
    "        width = self.dataset_width\n",
    "        height = self.dataset_height\n",
    "        geo_transform = self.dataset_geo_transform\n",
    "        if self.print_info:\n",
    "            print(f\"Creating dataset {self.dataset_prefix}{time_formated_start}.tif\"\n",
    "                f\" with width {width}, height {height}, geo_transform {geo_transform}\")\n",
    "        \n",
    "        \n",
    "        gdal_driver = gdal.GetDriverByName(self.gdal_driver)     \n",
    "        gdal_dataset = gdal_driver.Create(\n",
    "            f\"{self.dataset_prefix}{time_formated_start}.tif\",\n",
    "            width, height, len(self.bands),\n",
    "            gdal.GDT_Float32,\n",
    "            options=self.options\n",
    "        )\n",
    "        \n",
    "        gdal_dataset.SetGeoTransform(geo_transform)\n",
    "        gdal_dataset.SetProjection(query.srs)\n",
    "\n",
    "        for i, band in enumerate(self.bands):\n",
    "            gdal_band = gdal_dataset.GetRasterBand(i+1)\n",
    "            gdal_band.SetNoDataValue(self.no_data_value)\n",
    "            gdal_band.SetDescription(f\"{band.name} [{band.measurement}]\")\n",
    "\n",
    "\n",
    "        self.current_dataset = gdal_dataset\n",
    "        \n",
    "\n",
    "    async def query_and_write(self, query: ge.QueryRectangle):\n",
    "        self.create_tiling_geo_transform_width_height(query)\n",
    "        try:\n",
    "            async for tile in self.workflow.raster_stream(query):\n",
    "                if self.current_time != tile.time:\n",
    "                    self.close_current_dataset()\n",
    "                    self.current_time = tile.time\n",
    "                    self.create_new_dataset(query)\n",
    "                \n",
    "                assert self.current_time == tile.time, \"The time of the current dataset does not match the tile\"\n",
    "\n",
    "                tile_ul_x = int((tile.geo_transform.x_min - self.dataset_geo_transform[0] ) / self.dataset_geo_transform[1])\n",
    "                tile_ul_y = int((tile.geo_transform.y_max - self.dataset_geo_transform[3] )/ self.dataset_geo_transform[5])\n",
    " \n",
    "                band_index = tile.band + 1\n",
    "                data = tile.to_numpy_data_array(self.no_data_value)\n",
    "\n",
    "                assert self.tile_size == tile.size_x == tile.size_y, \"The tile size does not match the expected tile size\"\n",
    "\n",
    "                self.current_dataset.GetRasterBand(band_index).WriteArray(data, tile_ul_x, tile_ul_y)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error while processing tile at {tile.spatial_partition()} with {tile.time}\") from e\n",
    "\n",
    "        finally:\n",
    "            self.close_current_dataset()\n",
    "\n",
    "\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/git/geoengine-python/geoengine/workflow.py:598\u001b[0m, in \u001b[0;36mWorkflow.raster_stream.<locals>.read_new_bytes\u001b[0;34m()\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     data: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m websocket\u001b[38;5;241m.\u001b[39mrecv()\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;66;03m# the server sent an error message\u001b[39;00m\n",
      "File \u001b[0;32m~/git/geoengine-python/env/lib/python3.10/site-packages/websockets/legacy/protocol.py:551\u001b[0m, in \u001b[0;36mWebSocketCommonProtocol.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;66;03m# If asyncio.wait() is canceled, it doesn't cancel\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# pop_message_waiter and self.transfer_data_task.\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    552\u001b[0m         [pop_message_waiter, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransfer_data_task],\n\u001b[1;32m    553\u001b[0m         return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_COMPLETED,\n\u001b[1;32m    554\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloop_if_py_lt_38(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop),\n\u001b[1;32m    555\u001b[0m     )\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:384\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    382\u001b[0m fs \u001b[38;5;241m=\u001b[39m {ensure_future(f, loop\u001b[38;5;241m=\u001b[39mloop) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs}\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _wait(fs, timeout, return_when, loop)\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:491\u001b[0m, in \u001b[0;36m_wait\u001b[0;34m(fs, timeout, return_when, loop)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name[\u001b[38;5;241m37\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m writer \u001b[38;5;241m=\u001b[39m ge\u001b[38;5;241m.\u001b[39mRasterWorkflowGdalWriter(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name[\u001b[38;5;241m37\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, reg_workflow, no_data_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, data_type\u001b[38;5;241m=\u001b[39mgdal\u001b[38;5;241m.\u001b[39mGDT_Int16)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m writer\u001b[38;5;241m.\u001b[39mquery_and_write(query)\n",
      "File \u001b[0;32m~/git/geoengine-python/geoengine/raster_workflow_gdal_writer.py:167\u001b[0m, in \u001b[0;36mRasterWorkflowGdalWriter.query_and_write\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkflow \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe workflow must be set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tile \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkflow\u001b[38;5;241m.\u001b[39mraster_stream(query):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_time \u001b[38;5;241m!=\u001b[39m tile\u001b[38;5;241m.\u001b[39mtime:\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_current_dataset()\n",
      "File \u001b[0;32m~/git/geoengine-python/geoengine/workflow.py:609\u001b[0m, in \u001b[0;36mWorkflow.raster_stream\u001b[0;34m(self, query_rectangle, open_timeout, bands)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m websockets\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionClosedOK:\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;66;03m# the websocket connection closed gracefully, so we stop reading\u001b[39;00m\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m (tile_bytes, tile) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    610\u001b[0m     read_new_bytes(),\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;66;03m# asyncio.to_thread(process_bytes, tile_bytes), # TODO: use this when min Python version is 3.9\u001b[39;00m\n\u001b[1;32m    612\u001b[0m     backports\u001b[38;5;241m.\u001b[39mto_thread(RasterStreamProcessing\u001b[38;5;241m.\u001b[39mprocess_bytes, tile_bytes),\n\u001b[1;32m    613\u001b[0m )\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m tile\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from osgeo import gdal\n",
    "\n",
    "test_mode = True\n",
    "download_dir = \"./test/raw_data\"\n",
    "\n",
    "for (i, (tile, tb)) in enumerate(better_tiles.items()):\n",
    "    if test_mode and i > 0:\n",
    "        break\n",
    "    for band in band_names + [scl_name]:\n",
    "        if test_mode and i > 0:\n",
    "            break\n",
    "        dataset_name = get_dataset_name(user_id, tile, band)\n",
    "        workflow = ge.workflow_builder.operators.GdalSource(dataset_name)\n",
    "        reg_workflow = ge.register_workflow(workflow)\n",
    "\n",
    "        query = create_query(tb, get_band_resolution(band), time_start, time_end)\n",
    "\n",
    "        if not os.path.exists(f\"{download_dir}{dataset_name[37:]}/\"):\n",
    "            os.makedirs(f\"{download_dir}/{dataset_name[37:]}/\", exist_ok=True)\n",
    "\n",
    "        writer = ge.RasterWorkflowGdalWriter(f\"{download_dir}/{dataset_name[37:]}/\", reg_workflow, no_data_value=0, data_type=gdal.GDT_Int16)\n",
    "\n",
    "        await writer.query_and_write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download scaled, cloud free data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_mode = True\n",
    "download_dir = \"./test/scaled_cloud_free\"\n",
    "\n",
    "def create_cloud_free_scaled_workflow(user_id, tile, band):\n",
    "    dataset_name = get_dataset_name(user_id, tile, band)\n",
    "    scl_dataset_name = get_dataset_name(user_id, tile, scl_name)\n",
    "    workflow =ge.workflow_builder.blueprints.sentinel2_cloud_free_band_custom_input(\n",
    "        band_dataset=dataset_name,\n",
    "        scl_dataset=scl_dataset_name,\n",
    "    )\n",
    "    workflow = ge.workflow_builder.operators.RasterTypeConversion(workflow, output_data_type=\"F32\") # to float\n",
    "    workflow = ge.workflow_builder.operators.RasterScaling(workflow, slope=0.00001, offset=0.0) # to reflectance    \n",
    "    return workflow\n",
    "\n",
    "for (i, (tile, tb)) in enumerate(better_tiles.items()):\n",
    "    scl_dataset_name = get_dataset_name(user_id, tile, scl_name)\n",
    "\n",
    "    if test_mode and i > 0:\n",
    "        break\n",
    "    for band in band_names:\n",
    "        if test_mode and i > 0:\n",
    "            break\n",
    "        dataset_name = get_dataset_name(user_id, tile, band)\n",
    "\n",
    "        workflow = create_cloud_free_scaled_workflow(user_id, tile, band)\n",
    "        reg_workflow = ge.register_workflow(workflow)\n",
    "\n",
    "        query = create_query(tb, get_band_resolution(band), time_start, time_end)\n",
    "\n",
    "        if not os.path.exists(f\"{download_dir}{dataset_name[37:]}/\"):\n",
    "            os.makedirs(f\"{download_dir}/{dataset_name[37:]}/\", exist_ok=True)\n",
    "\n",
    "        writer = ge.RasterWorkflowGdalWriter(f\"{download_dir}/{dataset_name[37:]}/\", reg_workflow, no_data_value=0)\n",
    "\n",
    "        await writer.query_and_write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download weekly scaled data + NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_mode = True\n",
    "download_dir = \"./test/scaled_cloud_free_7days\"\n",
    "\n",
    "def create_cloud_free_scaled_workflow(user_id, tile, band):\n",
    "    dataset_name = get_dataset_name(user_id, tile, band)\n",
    "    scl_dataset_name = get_dataset_name(user_id, tile, scl_name)\n",
    "    workflow =ge.workflow_builder.blueprints.sentinel2_cloud_free_band_custom_input(\n",
    "        band_dataset=dataset_name,\n",
    "        scl_dataset=scl_dataset_name,\n",
    "    )\n",
    "    workflow = ge.workflow_builder.operators.RasterTypeConversion(workflow, output_data_type=\"F32\") # to float\n",
    "    workflow = ge.workflow_builder.operators.RasterScaling(workflow, slope=0.0001, offset=0.0) # to reflectance    \n",
    "    return workflow\n",
    "\n",
    "def create_cloud_free_scaled_workflow_7day_mean(user_id, tile, band):\n",
    "    workflow = create_cloud_free_scaled_workflow(user_id, tile, band)\n",
    "    workflow = ge.workflow_builder.operators.TemporalRasterAggregation(workflow, aggregation_type=\"mean\", granularity='days', window_size=7, ignore_no_data=True)\n",
    "    return workflow\n",
    "\n",
    "def create_cloud_free_scaled_workflow_7day_mean_ndvi(user_id, tile):\n",
    "    nir_workflow = create_cloud_free_scaled_workflow_7day_mean(user_id, tile, \"B08\")\n",
    "    red_workflow = create_cloud_free_scaled_workflow_7day_mean(user_id, tile, \"B04\")\n",
    "    stacked_workflow = ge.workflow_builder.operators.RasterStacker([nir_workflow, red_workflow])\n",
    "    ndvi_workflow = ge.workflow_builder.operators.Expression(\"(A-B)/(A+B)\", stacked_workflow, \"F32\", map_no_data=False)\n",
    "    return ndvi_workflow\n",
    "\n",
    "\n",
    "for (i, (tile, tb)) in enumerate(better_tiles.items()):\n",
    "    scl_dataset_name = get_dataset_name(user_id, tile, scl_name)\n",
    "    \n",
    "    for band in band_names:        \n",
    "        dataset_name = get_dataset_name(user_id, tile, band)\n",
    "\n",
    "        workflow = create_cloud_free_scaled_workflow_7day_mean(user_id, tile, band)\n",
    "        reg_workflow = ge.register_workflow(workflow)\n",
    "        query = create_query(tb, get_band_resolution(band), time_start, time_end)\n",
    "\n",
    "        if not os.path.exists(f\"{download_dir}{dataset_name[37:]}/\"):\n",
    "            os.makedirs(f\"{download_dir}/{dataset_name[37:]}/\", exist_ok=True)\n",
    "\n",
    "        writer = ge.RasterWorkflowGdalWriter(f\"{download_dir}/{dataset_name[37:]}/\", reg_workflow, no_data_value=0)\n",
    "        await writer.query_and_write(query)\n",
    "\n",
    "    # ndvi workflow    \n",
    "    workflow = create_cloud_free_scaled_workflow_7day_mean_ndvi(user_id, tile)\n",
    "    reg_workflow = ge.register_workflow(workflow)\n",
    "    query = create_query(tb, 10, time_start, time_end)\n",
    "    dataset_name = get_dataset_name(user_id, tile, \"NDVI\")\n",
    "\n",
    "    if not os.path.exists(f\"{download_dir}/ndvi/\"):\n",
    "        os.makedirs(f\"{download_dir}/ndvi/\", exist_ok=True)\n",
    "        \n",
    "    writer = ge.RasterWorkflowGdalWriter(f\"{download_dir}/ndvi/\", reg_workflow, no_data_value=-2)\n",
    "    await writer.query_and_write(query)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
