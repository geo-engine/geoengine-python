{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import geoengine as ge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Geo Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge.initialize(\"http://localhost:3030/api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Server:              http://localhost:3030/api\n",
       "User Id:             88e0f901-ba4f-41ba-a35e-a5b96a8f9ff9\n",
       "Session Id:          e19949d5-33de-4c85-ab1b-16bedbb8f6fb\n",
       "Session valid until: 2025-10-14T19:34:14.203Z"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = ge.get_session()\n",
    "user_id = session.user_id\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information about the bands we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_resolutions = {\"10\": [\"B02\", \"B03\", \"B04\", \"B08\"], \"20\": [\"B11\", \"B12\", \"SCL\"]}\n",
    "\n",
    "band_names = [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\"]\n",
    "scl_name = \"SCL\"\n",
    "\n",
    "\n",
    "def get_band_resolution(band_name):\n",
    "    if band_name == \"NDVI\":\n",
    "        return 10\n",
    "\n",
    "    for res, bands in band_resolutions.items():\n",
    "        if band_name in bands:\n",
    "            return float(res)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_resoluton_bands(res):\n",
    "    return band_resolutions[res]\n",
    "\n",
    "\n",
    "get_band_resolution(\"B02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tiles we want to use and way to modify the bounds to match the pixel resolution of the band (also use a power of 2 because it is nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [677000, 5888000, 678280, 5889280]\n",
      "1 1280 1280\n"
     ]
    }
   ],
   "source": [
    "def next_power_of_2(x):\n",
    "    return 1 if x == 0 else 2 ** math.ceil(math.log2(x))\n",
    "\n",
    "\n",
    "def better_tile_bounds(xmin, ymin, xmax, ymax, res):\n",
    "    size_x = xmax - xmin\n",
    "    size_y = ymax - ymin\n",
    "    x_start = int(xmin / res) * res\n",
    "    y_start = int(ymin / res) * res\n",
    "    x_end = x_start + next_power_of_2(size_x / res) * res\n",
    "    y_end = y_start + next_power_of_2(size_y / res) * res\n",
    "    return [x_start, y_start, x_end, y_end]\n",
    "\n",
    "\n",
    "tiles = {\n",
    "    \"1\": [677000.0, 5888000.0, 678000.0, 5889000.0],  # 1\n",
    "}\n",
    "\n",
    "max_pixel_size = int(get_band_resolution(\"B12\"))\n",
    "\n",
    "better_tiles = {b: better_tile_bounds(*tiles[b], max_pixel_size) for b in tiles}\n",
    "\n",
    "for tile, tile_bounds in better_tiles.items():\n",
    "    print(tile, tile_bounds)\n",
    "    [xmin, ymin, xmax, ymax] = tile_bounds\n",
    "    size_x = xmax - xmin\n",
    "    size_y = ymax - ymin\n",
    "    print(tile, size_x, size_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, the tiles are stored as different datasets. Here is a simple way to resolve there names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'88e0f901-ba4f-41ba-a35e-a5b96a8f9ff9:large_raster_download_sentinel2_10m_tile_10_band_B02_2022_2023'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataset_name(user_id, tile, band):\n",
    "    band_resolution = int(get_band_resolution(band))\n",
    "    return f\"{user_id}:large_raster_download_sentinel2_{band_resolution}m_tile_{tile}_band_{band}_2022_2023\"\n",
    "\n",
    "\n",
    "get_dataset_name(user_id, \"10\", \"B02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Geo Engine uses a `QueryRectangle` to request the data. It specifies the bounding box of the area of interest and the time range. (The resolution is also specified here, but this will change in the near future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryRectangle( \n",
       "    BoundingBox2D(xmin=677000, ymin=5888000, xmax=678280, ymax=5889280)\n",
       "    TimeInterval(start=2022-01-01T00:00:00.000000, end=2023-01-01T00:00:00.000000)\n",
       "    SpatialResolution(x=10.0, y=10.0)\n",
       "    srs=EPSG:32632 \n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_query(bounds, resolution, time_start, time_end):\n",
    "    [xmin, ymin, xmax, ymax] = bounds\n",
    "    return ge.QueryRectangle(\n",
    "        spatial_bounds=ge.BoundingBox2D(xmin, ymin, xmax, ymax),\n",
    "        time_interval=ge.TimeInterval(time_start, time_end),\n",
    "        resolution=ge.SpatialResolution(resolution, resolution),\n",
    "        srs=\"EPSG:32632\",\n",
    "    )\n",
    "\n",
    "\n",
    "time_start = datetime(2022, 1, 1)\n",
    "time_end = datetime(2023, 1, 1)\n",
    "\n",
    "create_query(better_tiles[\"1\"], 10.0, time_start, time_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestException",
     "evalue": "UnknownDataId: Unknown data id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m dataset_name = get_dataset_name(user_id, tile, band)\n\u001b[32m      5\u001b[39m workflow = ge.workflow_builder.blueprints.sentinel2_band(band_name=band)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m reg_workflow = \u001b[43mge\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m query = create_query(tb, get_band_resolution(band), time_start, time_end)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdataset_name[\u001b[32m37\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/geoengine-python2/geoengine/workflow.py:961\u001b[39m, in \u001b[36mregister_workflow\u001b[39m\u001b[34m(workflow, timeout)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m geoengine_openapi_client.ApiClient(session.configuration) \u001b[38;5;28;01mas\u001b[39;00m api_client:\n\u001b[32m    960\u001b[39m     workflows_api = geoengine_openapi_client.WorkflowsApi(api_client)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     response = \u001b[43mworkflows_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_workflow_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Workflow(WorkflowId.from_response(response))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/geoengine-python2/env/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/geoengine-python2/env/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/geoengine-python2/env/lib/python3.12/site-packages/geoengine_openapi_client/api/workflows_api.py:1765\u001b[39m, in \u001b[36mWorkflowsApi.register_workflow_handler\u001b[39m\u001b[34m(self, workflow, _request_timeout, _request_auth, _content_type, _headers, _host_index)\u001b[39m\n\u001b[32m   1760\u001b[39m response_data = \u001b[38;5;28mself\u001b[39m.api_client.call_api(\n\u001b[32m   1761\u001b[39m     *_param,\n\u001b[32m   1762\u001b[39m     _request_timeout=_request_timeout\n\u001b[32m   1763\u001b[39m )\n\u001b[32m   1764\u001b[39m response_data.read()\n\u001b[32m-> \u001b[39m\u001b[32m1765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse_deserialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1767\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_types_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_response_types_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1768\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/geoengine-python2/env/lib/python3.12/site-packages/geoengine_openapi_client/api_client.py:323\u001b[39m, in \u001b[36mApiClient.response_deserialize\u001b[39m\u001b[34m(self, response_data, response_types_map)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= response_data.status <= \u001b[32m299\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mApiException\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhttp_resp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ApiResponse(\n\u001b[32m    330\u001b[39m     status_code = response_data.status,\n\u001b[32m    331\u001b[39m     data = return_data,\n\u001b[32m    332\u001b[39m     headers = response_data.getheaders(),\n\u001b[32m    333\u001b[39m     raw_data = response_data.data\n\u001b[32m    334\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/geoengine-python2/env/lib/python3.12/site-packages/geoengine_openapi_client/exceptions.py:143\u001b[39m, in \u001b[36mApiException.from_response\u001b[39m\u001b[34m(cls, http_resp, body, data)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_response\u001b[39m(\n\u001b[32m    136\u001b[39m     \u001b[38;5;28mcls\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m     data: Optional[Any],\n\u001b[32m    141\u001b[39m ) -> Self:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m http_resp.status == \u001b[32m400\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m BadRequestException(http_resp=http_resp, body=body, data=data)\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m http_resp.status == \u001b[32m401\u001b[39m:\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedException(http_resp=http_resp, body=body, data=data)\n",
      "\u001b[31mBadRequestException\u001b[39m: UnknownDataId: Unknown data id"
     ]
    }
   ],
   "source": [
    "download_dir = \"./test/raw_data\"\n",
    "for _i, (tile, tb) in enumerate(better_tiles.items()):\n",
    "    for band in band_names + [scl_name]:\n",
    "        dataset_name = get_dataset_name(user_id, tile, band)\n",
    "        workflow = ge.workflow_builder.blueprints.sentinel2_band(band_name=band)\n",
    "        reg_workflow = ge.register_workflow(workflow)\n",
    "\n",
    "        query = create_query(tb, get_band_resolution(band), time_start, time_end)\n",
    "\n",
    "        if not os.path.exists(f\"{download_dir}{dataset_name[37:]}/\"):\n",
    "            os.makedirs(f\"{download_dir}/{dataset_name[37:]}/\", exist_ok=True)\n",
    "\n",
    "        writer = ge.RasterWorkflowRioWriter(f\"{download_dir}/{dataset_name[37:]}/\", reg_workflow, no_data_value=0)\n",
    "\n",
    "        await writer.query_and_write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download scaled, cloud free data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode = True\n",
    "download_dir = \"./test/scaled_cloud_free\"\n",
    "\n",
    "\n",
    "def create_cloud_free_scaled_workflow(_user_id, _tile, band):\n",
    "    # dataset_name = get_dataset_name(user_id, tile, band)\n",
    "    # scl_dataset_name = get_dataset_name(user_id, tile, scl_name)\n",
    "    workflow = ge.workflow_builder.blueprints.sentinel2_cloud_free_band(band_name=band)\n",
    "    workflow = ge.workflow_builder.operators.RasterTypeConversion(workflow, output_data_type=\"F32\")  # to float\n",
    "    workflow = ge.workflow_builder.operators.RasterScaling(workflow, slope=0.00001, offset=0.0)  # to reflectance\n",
    "    return workflow\n",
    "\n",
    "\n",
    "for i, (tile, tb) in enumerate(better_tiles.items()):\n",
    "    scl_dataset_name = get_dataset_name(user_id, tile, scl_name)\n",
    "\n",
    "    if test_mode and i > 0:\n",
    "        break\n",
    "    for band in band_names:\n",
    "        if test_mode and i > 0:\n",
    "            break\n",
    "        dataset_name = get_dataset_name(user_id, tile, band)\n",
    "\n",
    "        workflow = create_cloud_free_scaled_workflow(user_id, tile, band)\n",
    "        reg_workflow = ge.register_workflow(workflow)\n",
    "\n",
    "        query = create_query(tb, get_band_resolution(band), time_start, time_end)\n",
    "\n",
    "        if not os.path.exists(f\"{download_dir}{dataset_name[37:]}/\"):\n",
    "            os.makedirs(f\"{download_dir}/{dataset_name[37:]}/\", exist_ok=True)\n",
    "\n",
    "        writer = ge.RasterWorkflowRioWriter(f\"{download_dir}/{dataset_name[37:]}/\", reg_workflow, no_data_value=0)\n",
    "\n",
    "        await writer.query_and_write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download weekly scaled data + NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = \"./test/scaled_cloud_free_7days\"\n",
    "\n",
    "\n",
    "def create_cloud_free_scaled_workflow(_user_id, _tile, band):\n",
    "    # dataset_name = get_dataset_name(user_id, tile, band)\n",
    "    # scl_dataset_name = get_dataset_name(user_id, tile, scl_name)\n",
    "    workflow = ge.workflow_builder.blueprints.sentinel2_cloud_free_band(band_name=band)\n",
    "    workflow = ge.workflow_builder.operators.RasterTypeConversion(workflow, output_data_type=\"F32\")  # to float\n",
    "    workflow = ge.workflow_builder.operators.RasterScaling(workflow, slope=0.0001, offset=0.0)  # to reflectance\n",
    "    return workflow\n",
    "\n",
    "\n",
    "def create_cloud_free_scaled_workflow_7day_mean(user_id, tile, band):\n",
    "    workflow = create_cloud_free_scaled_workflow(user_id, tile, band)\n",
    "    workflow = ge.workflow_builder.operators.TemporalRasterAggregation(\n",
    "        workflow, aggregation_type=\"mean\", granularity=\"days\", window_size=7, ignore_no_data=True\n",
    "    )\n",
    "    return workflow\n",
    "\n",
    "\n",
    "def create_cloud_free_scaled_workflow_7day_mean_ndvi(_user_id, _tile):\n",
    "    # nir_workflow = create_cloud_free_scaled_workflow_7day_mean(user_id, tile, \"B08\")\n",
    "    # red_workflow = create_cloud_free_scaled_workflow_7day_mean(user_id, tile, \"B04\")\n",
    "    # stacked_workflow = ge.workflow_builder.operators.RasterStacker([nir_workflow, red_workflow])\n",
    "    # ndvi_workflow = ge.workflow_builder.operators.Expression(\"(A-B)/(A+B)\", stacked_workflow, \"F32\", map_no_data=False)  # noqa: E501\n",
    "    ndvi_workflow = ge.workflow_builder.blueprints.sentinel2_cloud_free_ndvi()\n",
    "    workflow = ge.workflow_builder.operators.TemporalRasterAggregation(\n",
    "        ndvi_workflow, aggregation_type=\"mean\", granularity=\"days\", window_size=7, ignore_no_data=True\n",
    "    )\n",
    "    return workflow\n",
    "\n",
    "\n",
    "for _i, (tile, tb) in enumerate(better_tiles.items()):\n",
    "    scl_dataset_name = get_dataset_name(user_id, tile, scl_name)\n",
    "\n",
    "    for band in band_names:\n",
    "        dataset_name = get_dataset_name(user_id, tile, band)\n",
    "\n",
    "        workflow = create_cloud_free_scaled_workflow_7day_mean(user_id, tile, band)\n",
    "        reg_workflow = ge.register_workflow(workflow)\n",
    "        query = create_query(tb, get_band_resolution(band), time_start, time_end)\n",
    "\n",
    "        if not os.path.exists(f\"{download_dir}{dataset_name[37:]}/\"):\n",
    "            os.makedirs(f\"{download_dir}/{dataset_name[37:]}/\", exist_ok=True)\n",
    "\n",
    "        writer = ge.RasterWorkflowRioWriter(f\"{download_dir}/{dataset_name[37:]}/\", reg_workflow, no_data_value=0)\n",
    "        await writer.query_and_write(query)\n",
    "\n",
    "    # ndvi workflow\n",
    "    workflow = create_cloud_free_scaled_workflow_7day_mean_ndvi(user_id, tile)\n",
    "    reg_workflow = ge.register_workflow(workflow)\n",
    "    query = create_query(tb, 10, time_start, time_end)\n",
    "    dataset_name = get_dataset_name(user_id, tile, \"NDVI\")\n",
    "\n",
    "    if not os.path.exists(f\"{download_dir}/ndvi/\"):\n",
    "        os.makedirs(f\"{download_dir}/ndvi/\", exist_ok=True)\n",
    "\n",
    "    writer = ge.RasterWorkflowRioWriter(f\"{download_dir}/ndvi/\", reg_workflow, no_data_value=-2)\n",
    "    await writer.query_and_write(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
